---
title: "diaspara habitat database creation script"
subtitle: "DIASPARA WP3.1 working document"
author: "Oliviéro Jules, Briand Cédric, Helminen Jani"
date: last-modified
date-format: "DD-MM-YYYY"
description: "Design an international database of habitat of migratory fish, version = build"
title-block-banner: "images/diaspara_bandeau.png"
title-block-banner-color: "white"
format:
 html:
  code-fold: true
  code-tools: true
  self-contained: true
  theme: styles.scss
  smooth-scroll: true
  fontcolor: black
  toc: true
  toc-location: left
  toc-title: Summary
  toc-depth: 3
execute: 
 keep-md: true
filters:
  - include-code-files
reference-location: document
bibliography: diaspara.bib
include-after-body: "footer.html"
---


# Choice of 2 river networks
To create the habitat database we decided to use two river networks in parallel.
The Hydrological data and maps based on SHuttle Elevation Derivatives at multiple Scales (**HydroSHEDS**) and **EU-Hydro** from Copernicus (European Union's Earth Observation Programme).

**EU-Hydro**, being an European only dataset, will not include the Southern Mediterranean.

# HydroSHEDS
## Data description
**HydroSHEDS** is a global database providing high-resolution hydrographic data derived from NASA's Shuttle Radar Topography Mission (SRTM). Covering most land areas, it offers structured datasets for hydrological modeling, watershed analysis, and environmental research. The data is available at resolutions up to 3 arc-seconds (~90m) in raster (GeoTIFF) and vector (shapefiles,geodatabases) formats. 
We opted to use the geodatabases format. It includes river networks, watershed boundaries, drainage directions, and flow accumulation. Core products include **HydroBASINS** for watershed boundaries, **HydroRIVERS** for river networks, **HydroLAKES** for lakes and reservoirs, and **HydroATLAS**, which adds environmental attributes.


```{r init}
#| echo: FALSE
#| warning: FALSE
#| message: FALSE
#| results: 'hide'

#if (!grepl("montepomi", getwd())) {
if(Sys.info()[["user"]] == 'joliviero'){
setwd("D:/workspace/DIASPARA_WP3_habitat/R")
datawd <- "D:/DIASPARA/wgbast"
} else if (Sys.info()[["user"]] == 'cedric.briand'){
setwd("C:/workspace/DIASPARA_WP3_habitat/R")
datawd <- "C:/Users/cedric.briand/OneDrive - EPTB Vilaine/Projets/DIASPARA/wgbast"
}
source("utilities/load_library.R")
load_library("tidyverse")
load_library("knitr")
load_library("kableExtra")
load_library("icesVocab")
load_library("readxl")
load_library("janitor")
load_library("skimr")
load_library("RPostgres")
load_library("yaml")
load_library("DBI")
load_library("ggplot2")
load_library("sf")
load_library("janitor") # clean_names
load_library("rnaturalearth")
cred <- read_yaml("../credentials.yml")
con_diaspara <- dbConnect(Postgres(), 
                           dbname = cred$dbnamehydro,
                           host = cred$host,
                           port = cred$port,
                           user = cred$userdiaspara,
                           password = cred$passworddiaspara)
con_diaspara_admin <- dbConnect(Postgres(), 
                           dbname = cred$dbnamehydro,
                           host = cred$host,
                           port = cred$port,
                           user = cred$usersalmo,
                           password = cred$passwordsalmo)





```


<details>
<summary>Descriptions of riversegments variables</summary>

```{r}
#| label: riversegment variables
#| echo: TRUE
#| warning: FALSE
#| message: FALSE
#| tbl-cap: Variables description


data_description <- dbGetQuery(con_diaspara, 
  "SELECT cols.column_name AS var_name, 
        pgd.description AS description
  FROM information_schema.columns cols
  LEFT JOIN pg_catalog.pg_statio_all_tables st 
      ON st.schemaname = cols.table_schema AND st.relname = cols.table_name
  LEFT JOIN pg_catalog.pg_description pgd 
      ON pgd.objoid = st.relid AND pgd.objsubid = cols.ordinal_position
  WHERE cols.table_schema = 'riveratlas'
  AND cols.table_name = 'riveratlas_v10';")

knitr::kable(data_description) %>% kable_styling(bootstrap_options = c("striped", "hover", "condensed"))

```

</details>



## Importing HydroSHEDS
The first thing is to download and process the hydrological network from the **HydroSHEDS** website. To do so we created a PowerShell script that iterates through predefined file IDs (`$files`) and corresponding dataset types (`$atlas`), constructing download URLs and filenames dynamically. The script navigates to the source directory, downloads each dataset as a ZIP file using `curl`, extracts it to a specified output directory, and then connects to the PostgreSQL database (`diaspara`). Within the database, it ensures a cleanschema by dropping any existing schema of the same name and recreating it for fresh data import.

<details> 
<summary>PowerShell code to download HydroSHEDS</summary>

```{.ps1 include="../bash/0_powershell_import_hydroatlas.ps1"}
```
</details> 

The same process has been used to import a country layer and ICES divisions.
ICES divisions are downloaded from the ICES website.

## Inserting data
Then we have to insert the downloaded data to the database. To do so we used `ogr2ogr`, a command-line tool from the GDAL library, to import geospatial data from File Geodatabases (GDB) into a PostgreSQL database. Each command processes a different dataset—**BasinATLAS, RiverATLAS, and LakeATLAS**—and loads them into corresponding schemas within the **DIASPARA** database.  

The `-f "PostgreSQL"` specifies the output format, while `-a_srs EPSG:4326` ensures the spatial reference system is set to WGS 84 (EPSG:4326). The `-lco SCHEMA="..."` option places each dataset into a designated schema (`basinatlas`, `riveratlas`, `lakeatlas`). The `-overwrite` flag ensures any existing data in the schema is replaced. The `-progress` option provides real-time feedback during execution. Lastly, `--config PG_USE_COPY YES` optimizes performance by using PostgreSQL's `COPY` command for faster data insertion.

<details>
<summary>Code to import data to the database</summary>

```{.ps1 include="../bash/1_osgeo4w_ogr2ogr_gdb_postgres_hydroatlas.ps1"}
```
</details>

The same process is used to insert other downloaded data to the database.


## Building the database
Once the data downloaded we chose to to split the database into smaller groups following ICES Areas and Ecoregions.

### Step 1 : Spliting data into smaller groups for efficiency (Europe/N.Africa)

We decided to extract European hydrological data by first selecting large-scale catchments from `basinatlas.basinatlas_v10_lev03`, a layer representing coarse-resolution catchments at level 3. We filtered these catchments based on specific `hybas_id` values and stored them in a temporary table `tempo.hydro_large_catchments_europe`. Next, we refined our selection by extracting smaller, more detailed catchments from `basinatlas.basinatlas_v10_lev12`, which represents the most detailed level (level 12) of the HydroBASINS hierarchy. We ensured that these smaller catchments were spatially contained within the large catchments using `ST_Within`, saving them in `tempo.hydro_small_catchments_europe`, and added a GIST index on geometries to improve spatial query efficiency. Finally, we selected river segments from `riveratlas.riveratlas_v10` that intersected with the chosen small catchments using `ST_Intersects`, storing the results in `tempo.hydro_riversegments_europe`.

```{sql}
#| label: smaller groups
#| code-summary: Code to split data into smaller entities
#| echo: TRUE
#| eval: FALSE
#| warning: FALSE
#| message: FALSE

-- Selecting european data from hydroatlas (large catchments)
DROP TABLE IF EXISTS tempo.hydro_large_catchments_europe;
CREATE TABLE tempo.hydro_large_catchments_europe AS(
SELECT shape FROM basinatlas.basinatlas_v10_lev03
WHERE hybas_id = ANY(ARRAY[2030000010,2030003440,2030005690,2030006590,
              2030006600,2030007930,2030007940,2030008490,2030008500,
							2030009230,2030012730,2030014550,2030016230,2030018240,2030020320,2030024230,2030026030,2030028220,
							2030030090,2030033480,2030037990,2030041390,2030045150,2030046500,2030047500,2030048590,2030048790,
							2030054200,2030056770,2030057170,2030059370,2030059450,2030059500,2030068680,2030059510])
);--35

-- Selecting european data from hydroatlas (small catchments)
DROP TABLE IF EXISTS tempo.hydro_small_catchments_europe;
CREATE TABLE tempo.hydro_small_catchments_europe AS (
SELECT * FROM basinatlas.basinatlas_v10_lev12 ba
WHERE EXISTS (
  SELECT 1
  FROM tempo.hydro_large_catchments_europe hlce
  WHERE ST_Within(ba.shape,hlce.shape)
  )
);--78055
CREATE INDEX idx_tempo_hydro_small_catchments_europe ON tempo.hydro_small_catchments_europe USING GIST(shape);

-- Selecting european data from riveratlas
DROP TABLE IF EXISTS tempo.hydro_riversegments_europe;
CREATE TABLE tempo.hydro_riversegments_europe AS(
	SELECT * FROM riveratlas.riveratlas_v10 r
	WHERE EXISTS (
		SELECT 1
		FROM tempo.hydro_small_catchments_europe e
		WHERE ST_Intersects(r.geom,e.shape)
	)
); --589947
```

The same method has been used to select catchemnts and river segments in the Southern Mediterranean area.

![Map of all catchemnts present in the database.](images/fig-all_catchments.png "A view of all European and Northern African catchments "){#fig-all_catchments}

### Step 2 : Selecting the most downstream riversegment for each reach

Next we needed to extract the most downstream river segments from `tempo.hydro_riversegments_europe`. To achieve this, we filtered the table to retain only the river segments where `hyriv_id` is equal to `main_riv`, which correspond to the most downstream river segment of the river basin, ensuring that for each reach, only its most downstream segment is selected. The results were then stored in `tempo.riveratlas_mds`.

```{sql}
#| label: most downstream rivers
#| code-summary: Code to select the most downstream river segments
#| echo: TRUE
#| eval: FALSE
#| warning: FALSE
#| message: FALSE

DROP TABLE IF EXISTS tempo.riveratlas_mds;
CREATE TABLE tempo.riveratlas_mds AS (
	SELECT *
	FROM tempo.hydro_riversegments_europe
	WHERE hydro_riversegments_europe.hyriv_id = hydro_riversegments_europe.main_riv); --17344
```

The same method has been used for Southern Mediterranean data.

![Map of most downstream river segments in the Baltic area.](images/fig-mds_baltic.png "A view of the Baltic with the most downstream river segments highlighted"){#fig-mds_baltic}

### Step 3 : Creating a most downstream point

To identify the most downstream point for each river segment in `tempo.riveratlas_mds`, a new column, `downstream_point`, was added to store the point geometry (EPSG:4326). The last coordinate of each segment’s geometry was extracted using `ST_PointN` on the cut down line geometry from `ST_Dump`, ensuring that the most downstream point was correctly identified. The table was then updated by assigning the extracted downstream point to the corresponding `hyriv_id`. Finally, a GIST index on `downstream_point` was created to improve the efficiency of spatial queries.

```{sql}
#| label: most downstream point
#| code-summary: Code to create the most downstream point
#| echo: TRUE
#| eval: FALSE
#| warning: FALSE
#| message: FALSE

ALTER TABLE tempo.riveratlas_mds
	ADD COLUMN downstream_point geometry(Point, 4326);
WITH downstream_points AS (
    SELECT 
        hyriv_id,
        ST_PointN((ST_Dump(geom)).geom, ST_NumPoints((ST_Dump(geom)).geom)) AS downstream_point
    FROM tempo.riveratlas_mds
)
UPDATE tempo.riveratlas_mds AS t
	SET downstream_point = dp.downstream_point
	FROM downstream_points AS dp
	WHERE t.hyriv_id = dp.hyriv_id; --17344

CREATE INDEX idx_tempo_riveratlas_mds_dwnstrm ON tempo.riveratlas_mds USING GIST(downstream_point);
```

The same method has been used for Southern Mediterranean data.

![Map of most downstream points in the Baltic area.](images/fig-mdp_baltic.png "A view of the Baltic with the most downstream points highlighted"){#fig-mdp_baltic}

### Step 4 : Intersecting the most downstream point with wanted ICES areas

#### Baltic

ICES divisions are already used in the Baltic by WGBAST thus we decided to keep the same structure. It is divided in three areas grouping together ICES divisions 30 & 31 ; 27,28,29 & 32 and 22,24,25 & 26.

![Map of ICES fishing areas at subdivision level, source NAFO, FAO, ICES, GFCM.](images/fig-ices_baltic.png "A view of the Baltic with ICES fishing subdivision"){#fig-ices_baltic}

A new table, `tempo.ices_areas_3229_27`, was created by selecting river segments from `tempo.riveratlas_mds` where the `downstream_point` of each segment is within a specified distance (0.01 units) of the geometry in `ices_areas."ices_areas_20160601_cut_dense_3857"`. The selection was further restricted to areas with specific `subdivisio` values ('32', '29', '28', '27'). Additionally, to avoid duplicates, only segments whose `downstream_point` is not already present in `tempo.ices_areas_3031` were included.
The same method is used for the whole Baltic area.

```{sql}
#| label: baltic downstream points
#| code-summary: Code to retrieve most downstream points for 27, 28, 29 & 32 ICES areas
#| eval: FALSE
#| echo: TRUE
#| warning: FALSE
#| message: FALSE

CREATE TABLE tempo.ices_areas_3229_27 AS (
	SELECT dp.*
	FROM tempo.riveratlas_mds AS dp
	JOIN ices_areas."ices_areas_20160601_cut_dense_3857" AS ia
	ON ST_DWithin(
	    dp.downstream_point,
	    ia.geom,
	    0.01
	)
	WHERE ia.subdivisio=ANY(ARRAY['32','29','28','27'])
	AND dp.downstream_point NOT IN (
		SELECT existing.downstream_point
	    FROM tempo.ices_areas_3031 AS existing)
); --569
```


![Map of most downstream points in the Northern Baltic ICES area.](images/fig-mdp_baltic2732.png "A view of the Northern Baltic with the most downstream points highlighted"){#fig-mdp_baltic2732}

#### Ecoregions

For the rest of the dataset, ICES ecoregions have been used to group catchments and river segments together.

![Map of ICES fishing ecoregions.](images/fig-ices_ecoregions.png "A view of Europe and Northern Africa with ICES fishing ecoregions"){#fig-ices_ecoregions}

We gathered the most downstream points from `tempo.riveratlas_mds`, applying three filters: a country filter, an ICES ecoregion filter, and an exclusion condition.  

First, we retrieved distinct downstream points that were within 0.04 degrees of the geometries in `ices_ecoregions.ices_ecoregions_20171207_erase_esri`, specifically selecting `objectid = 11`, which corresponded to the desired ICES ecoregion. Additionally, these points had to be within 0.02 degrees of the geometries in `tempo.ne_10m_admin_0_countries`, ensuring they were located in Norway or Sweden.  

Similarly, we selected downstream points that were within 0.04 degrees of the geometries in `ices_areas.ices_areas_20160601_cut_dense_3857`, specifically for `subdivisio = '23'`, while also ensuring they were within 0.02 degrees of Norway or Sweden. This is done because of an overlap between ICES ecoregions and ICES areas in this particular zone. 

Finally, we combined both sets of points while applying an exclusion condition: any points from the ICES area selection that already existed in the ICES ecoregion selection were removed, ensuring no duplicates while maintaining priority for the ecoregion-based selection. The resulting dataset `tempo.ices_ecoregions_nsea_north` contained the most downstream points filtered by ICES ecoregions, ICES areas, and country boundaries for Norway and Sweden.

```{sql}
#| label: northern north sea downstream points
#| code-summary: Code to retrieve most downstream points for the Northern part of the North Sea ICES ecoregion
#| eval: FALSE
#| echo: TRUE
#| warning: FALSE
#| message: FALSE

CREATE TABLE tempo.ices_ecoregions_nsea_north AS (
    WITH ecoregion_points AS (
        SELECT DISTINCT dp.*
        FROM tempo.riveratlas_mds AS dp
        JOIN ices_ecoregions."ices_ecoregions_20171207_erase_esri" AS er
        ON ST_DWithin(
            dp.downstream_point,
            er.geom,
            0.04
        )
        JOIN tempo.ne_10m_admin_0_countries AS cs
        ON ST_DWithin(
            dp.downstream_point,
            cs.geom,
            0.02
        )
        WHERE er.objectid = 11
          AND cs.name IN ('Norway','Sweden')
    ),
    area_points AS (
        SELECT DISTINCT dp.*
        FROM tempo.riveratlas_mds AS dp
        JOIN ices_areas."ices_areas_20160601_cut_dense_3857" AS ia
        ON ST_DWithin(
            dp.downstream_point,
            ia.geom,
            0.04
        )
        JOIN tempo.ne_10m_admin_0_countries AS cs
        ON ST_DWithin(
            dp.downstream_point,
            cs.geom,
            0.02
        )
        WHERE ia.subdivisio = '23'
          AND cs.name IN ('Norway','Sweden')
    )
    SELECT * FROM ecoregion_points
    UNION
    SELECT * FROM area_points
    WHERE downstream_point NOT IN (
        SELECT downstream_point FROM ecoregion_points
    )
);--1271
```

![Map of most downstream points in the Northern Sea.](images/fig-mdp_ecoregions.png "A view of the Northern Sea with the most downstream points highlighted"){#fig-mdp_ecoregions}

### Step 4.5 : Redo the intersection using a larger buffer to retrieve missing points

#### Baltic

We selected the most downstream points from `tempo.riveratlas_mds` that were within a larger buffer of 0.1 degrees of the geometries in `ices_areas.ices_areas_20160601_cut_dense_3857`, specifically for `subdivisio` values 32, 29, and 28 (subdivision 27 being already complete).

To avoid duplication, we compiled a list of excluded points by gathering all downstream points already present in several existing tables: `tempo.ices_areas_26_22`, `tempo.ices_areas_3229_27`, `tempo.ices_areas_3031`, `tempo.ices_ecoregions_barent`, `tempo.ices_ecoregions_nsea_north`, and `tempo.ices_ecoregions_norwegian`.  

We then identified the missing points by filtering out any downstream points from our selection that matched an already excluded point. This ensured that only new and unique points were retained.  
Finally, we inserted these missing points into `tempo.ices_areas_3229_27`.


```{sql}
#| eval: FALSE
#| echo: TRUE
#| code-summary: Code to retrieve missing most downstream points for 27, 28, 29 & 32 ICES areas using a larger buffer
#| warning: FALSE
#| message: FALSE

WITH filtered_points AS (
    SELECT dp.*
    FROM tempo.riveratlas_mds AS dp
    JOIN ices_areas."ices_areas_20160601_cut_dense_3857" AS ia
    ON ST_DWithin(
        dp.downstream_point,
        ST_Transform(ia.geom, 4326),
        0.1
    )
    WHERE ia.subdivisio = ANY(ARRAY['32', '29', '28'])
),
excluded_points AS (
    SELECT downstream_point
    FROM tempo.ices_areas_26_22
    UNION ALL
    SELECT downstream_point FROM tempo.ices_areas_3229_27
    UNION ALL
    SELECT downstream_point FROM tempo.ices_areas_3031
    UNION ALL
    SELECT downstream_point FROM tempo.ices_ecoregions_barent
    UNION ALL
    SELECT downstream_point FROM tempo.ices_ecoregions_nsea_north
    UNION ALL
    SELECT downstream_point FROM tempo.ices_ecoregions_norwegian
),
missing_points AS (
    SELECT fp.*
    FROM filtered_points AS fp
    LEFT JOIN excluded_points AS ep
    ON ST_Equals(fp.downstream_point, ep.downstream_point)
    WHERE ep.downstream_point IS NULL
)
INSERT INTO tempo.ices_areas_3229_27
SELECT mp.*
FROM missing_points AS mp;--8
```


#### Ecoregions

We selected distinct downstream points from `tempo.riveratlas_mds` using two spatial filters. The first selection included points within 0.1 degrees of `ices_ecoregions.ices_ecoregions_20171207_erase_esri`, specifically for `objectid = 11`, and also within the larger buffer of 0.1 degrees of `tempo.ne_10m_admin_0_countries`, ensuring they were in Norway or Sweden.  

The second selection included points within 0.1 degrees of `ices_areas.ices_areas_20160601_cut_dense_3857`, specifically for `subdivisio = '23'`, while also ensuring proximity to Norway or Sweden. Both selections were merged to form the set of filtered points.  

To prevent duplication, we compiled a list of excluded points by gathering all downstream points already present in several tables: `tempo.ices_areas_26_22`, `tempo.ices_areas_3229_27`, `tempo.ices_areas_3031`, `tempo.ices_ecoregions_barent`, `tempo.ices_ecoregions_nsea_north`, `tempo.ices_ecoregions_norwegian`, and `tempo.ices_ecoregions_nsea_south`.  

We then identified missing points by removing any downstream points from our selection that matched an already excluded point. This ensured that only new and unique points were retained.  

Finally, we inserted these missing points into `tempo.ices_ecoregions_nsea_north`, adding new downstream points that met the criteria while avoiding duplicates.

```{sql}
#| eval: FALSE
#| echo: TRUE
#| code-summary: Code to retrieve most downstream points for the Northern part of the North Sea ICES ecoregion with a larger buffer
#| warning: FALSE
#| message: FALSE

WITH filtered_points AS (
    SELECT DISTINCT dp.*
    FROM tempo.riveratlas_mds AS dp
    JOIN ices_ecoregions.ices_ecoregions_20171207_erase_esri AS er
    ON ST_DWithin(
        dp.downstream_point,
        ST_Transform(er.geom, 4326),
        0.1
    )
    JOIN tempo.ne_10m_admin_0_countries AS cs
    ON ST_DWithin(
        dp.downstream_point,
        ST_Transform(cs.geom, 4326),
        0.1
    )
    WHERE er.objectid = 11
      AND cs.name IN ('Norway', 'Sweden')

    UNION
    SELECT DISTINCT dp.*
    FROM tempo.riveratlas_mds AS dp
    JOIN ices_areas.ices_areas_20160601_cut_dense_3857 AS ia
    ON ST_DWithin(
        dp.downstream_point,
        ST_Transform(ia.geom, 4326),
        0.1
    )
    JOIN tempo.ne_10m_admin_0_countries AS cs
    ON ST_DWithin(
        dp.downstream_point,
        ST_Transform(cs.geom, 4326),
        0.1
    )
    WHERE ia.subdivisio = '23'
      AND cs.name IN ('Norway', 'Sweden')
),
excluded_points AS (
    SELECT downstream_point FROM tempo.ices_areas_26_22
    UNION ALL
    SELECT downstream_point FROM tempo.ices_areas_3229_27
    UNION ALL
    SELECT downstream_point FROM tempo.ices_areas_3031
    UNION ALL
    SELECT downstream_point FROM tempo.ices_ecoregions_barent
    UNION ALL
    SELECT downstream_point FROM tempo.ices_ecoregions_nsea_north
    UNION ALL
    SELECT downstream_point FROM tempo.ices_ecoregions_norwegian
    UNION ALL
    SELECT downstream_point FROM tempo.ices_ecoregions_nsea_south
),
missing_points AS (
    SELECT fp.*
    FROM filtered_points AS fp
    LEFT JOIN excluded_points AS ep
    ON ST_Equals(fp.downstream_point, ep.downstream_point)
    WHERE ep.downstream_point IS NULL
)
INSERT INTO tempo.ices_ecoregions_nsea_north
SELECT mp.*
FROM missing_points AS mp;
```

### Step 5 : Copy all riversegments corresponding to the previously selected riversegments using the main_riv identifier

A new schema `h_baltic_3229_27` was created to store the selected river segments. Within this schema, we created the `riversegments` table by selecting distinct river segments from `tempo.hydro_riversegments_europe` that matched the `main_riv` values found in `tempo.ices_areas_3229_27`. This ensured that only river segments associated with the relevant ICES subdivisions were included.  

To optimize the table, we added a primary key constraint on `hyriv_id`, ensuring data integrity and uniqueness. Additionally, two indexes were created: a **B-tree** index on `main_riv` to improve lookup efficiency and a **GIST** index on `geom` to speed up spatial queries.

```{sql}
#| eval: FALSE
#| echo: TRUE
#| code-summary: Code to retrieve all river segments corresponding to the selected area
#| warning: FALSE
#| message: FALSE

CREATE SCHEMA h_baltic_3229_27;
DROP TABLE IF EXISTS h_baltic_3229_27.riversegments;
CREATE TABLE h_baltic_3229_27.riversegments AS (
    SELECT DISTINCT ON (hre.geom) hre.*
    FROM tempo.hydro_riversegments_europe AS hre
    JOIN tempo.ices_areas_3229_27 AS ia
    ON hre.main_riv = ia.main_riv
);--30869

ALTER TABLE h_baltic_3229_27.riversegments
ADD CONSTRAINT pk_hyriv_id PRIMARY KEY (hyriv_id);

CREATE INDEX idx_h_baltic_3229_27_riversegments_main_riv ON h_baltic_3229_27.riversegments USING BTREE(main_riv);
CREATE INDEX idx_h_baltic_3229_27_riversegments ON h_baltic_3229_27.riversegments USING GIST(geom);
```

![Map of river segments for 27, 29-32 ICES areas.](images/fig-rs_baltic2732.png "A view of the Baltic with selected river segments for 27, 29-32 ICES areas"){#fig-rs_baltic2732}

### Step 6 : Gather all corresponding catchments using an intersection function

We created the `h_baltic_26_22.catchments` table by selecting distinct small catchments from `tempo.hydro_small_catchments_europe` that intersect with the river segments stored in `h_baltic_26_22.riversegments`. To avoid duplication, we excluded any catchments that were already present in `h_baltic_3031.catchments` or `h_baltic_3229_27.catchments`.  

To improve performance and maintain data integrity, we added a primary key constraint on `hybas_id`. Additionally, we created a **B-tree** index on `main_bas` to optimize lookups and a **GIST** index on `shape` to enhance spatial query efficiency.

```{sql}
#| eval: FALSE
#| echo: TRUE
#| code-summary: Code to retrieve all catchments corresponding to previously selected river segments
#| warning: FALSE
#| message: FALSE

DROP TABLE IF EXISTS h_baltic_26_22.catchments;
CREATE TABLE h_baltic_26_22.catchments AS (
    SELECT DISTINCT ON (hce.hybas_id) hce.*
    FROM tempo.hydro_small_catchments_europe AS hce
    JOIN h_baltic_26_22.riversegments AS rs
    ON ST_Intersects(hce.shape, rs.geom)
    LEFT JOIN (
        SELECT shape FROM h_baltic_3031.catchments
        UNION ALL
        SELECT shape FROM h_baltic_3229_27.catchments
    ) AS excluded
    ON hce.shape && excluded.shape
    AND ST_Equals(hce.shape, excluded.shape)
    WHERE excluded.shape IS NULL
);--3878

ALTER TABLE h_baltic_26_22.catchments
ADD CONSTRAINT pk_hybas_id PRIMARY KEY (hybas_id);

CREATE INDEX idx_h_baltic_26_22_catchments_main_bas ON h_baltic_26_22.catchments USING BTREE(main_bas);
CREATE INDEX idx_h_baltic_26_22_catchments ON h_baltic_26_22.catchments USING GIST(shape);
```

![Map of catchments for 27, 29-32 ICES areas.](images/fig-catch_baltic2732.png "A view of the Baltic with selected catchments for 27, 29-32 ICES areas"){#fig-catch_baltic2732}

### Step 7 : Retrieve all missing endorheic catchments using an evelope

We constructed the `tempo.oneendo_bisciber` table by generating a concave hull around the exterior boundary of the merged catchment shapes from `h_biscay_iberian.catchments`. This process created a generalized polygon representing the area covered by these catchments. To improve spatial query performance, we added a **GIST** index on the geometry column.  

Next, we identified endorheic basins from `basinatlas.basinatlas_v10_lev12` that intersected with `tempo.oneendo_bisciber`. To ensure only relevant basins were selected, we excluded those already present in surrounding areas (`h_biscay_iberian.catchments`, `h_med_west.catchments`, `h_nsea_south.catchments`), and specific basins defined by `main_bas` values 2120017150, 2120017480, and 2120018070 that belongs to another area. The remaining filtered basins were then inserted into `h_biscay_iberian.catchments`.

Finally, we populated `h_biscay_iberian.riversegments` by selecting distinct river segments from `tempo.hydro_riversegments_europe` that intersected with the newly added catchments. To prevent duplicate entries, we excluded any river segments that already existed in `h_biscay_iberian.riversegments`.

```{sql}
#| eval: FALSE
#| echo: TRUE
#| code-summary: Code to retrieve missing endorheic basins
#| warning: FALSE
#| message: FALSE

DROP TABLE IF EXISTS tempo.oneendo_bisciber;
CREATE TABLE tempo.oneendo_bisciber AS (
	SELECT  ST_ConcaveHull(ST_MakePolygon(ST_ExteriorRing((ST_Dump(ST_Union(ha.shape))).geom)),0.1,FALSE) geom
	FROM h_biscay_iberian.catchments AS ha);--67
CREATE INDEX idx_tempo_oneendo_bisciber ON tempo.oneendo_bisciber USING GIST(geom);
	

WITH endo_basins AS (	
    SELECT ba.*
    FROM basinatlas.basinatlas_v10_lev12 AS ba
    JOIN tempo.oneendo_bisciber
    ON ba.shape && oneendo_bisciber.geom
    AND ST_Intersects(ba.shape, oneendo_bisciber.geom)
),
excluded_basins AS (
    SELECT shape 
    FROM h_biscay_iberian.catchments
    UNION ALL
    SELECT shape 
    FROM h_med_west.catchments
    UNION ALL
    SELECT shape 
    FROM h_nsea_south.catchments
    UNION ALL
    SELECT shape
    FROM basinatlas.basinatlas_v10_lev12
    WHERE main_bas = ANY(ARRAY[2120017150, 2120017480, 2120018070])
),
filtered_basin AS (
    SELECT eb.*
    FROM endo_basins eb
    LEFT JOIN excluded_basins exb
    ON eb.shape && exb.shape
    AND ST_Equals(eb.shape, exb.shape)
    WHERE exb.shape IS NULL
)
INSERT INTO h_biscay_iberian.catchments
SELECT *
FROM filtered_basin;--62


INSERT INTO h_biscay_iberian.riversegments
SELECT DISTINCT ON (r.hyriv_id) r.*
FROM tempo.hydro_riversegments_europe r
JOIN h_biscay_iberian.catchments c
ON r.geom && c.shape
AND ST_Intersects(r.geom, c.shape)
WHERE NOT EXISTS (
    SELECT *
    FROM h_biscay_iberian.riversegments ex
    WHERE r.geom && ex.geom
    AND ST_Equals(r.geom, ex.geom)
);--57
```

![Map of catchemnts on the Iberian peninsula with missing endorheic basins.](images/fig-endo_biscay.png "A view of the Iberian peninsula with missing endorheic basins"){#fig-endo_biscay}

![Map of the concave hull on the Iberian peninsula.](images/fig-conc_biscay.png "A view of the concave hull on the Iberian peninsula"){#fig-conc_biscay}

![Map of catchemnts on the Iberian peninsula without missing endorheic basins.](images/fig-fendo_biscay.png "A view of the Iberian peninsula without missing endorheic basins"){#fig-fendo_biscay}


### Step 8 : Retrieve all missing islands and coastal catchments not linked to a riversegments by using an intersection with ICES areas

We identified the last set of catchments by selecting distinct small catchments from `tempo.hydro_small_catchments_europe` that intersected with `ices_areas.ices_areas_20160601_cut_dense_3857`, specifically within subdivisions 32, 29, 28, and 27.  

To avoid duplication, we excluded catchments that were already present in `h_baltic_3031.catchments`, `h_baltic_3229_27.catchments`, and `h_baltic_26_22.catchments`. The remaining catchments, which were not already accounted for, were inserted into `h_baltic_3229_27.catchments`.


```{sql}
#| eval: FALSE
#| echo: TRUE
#| code-summary: Code to retrieve all missing islands and coastal catchments
#| warning: FALSE
#| message: FALSE

WITH last_basin AS (
	SELECT DISTINCT ON (c.hybas_id) c.*
	FROM tempo.hydro_small_catchments_europe AS c
	JOIN ices_areas.ices_areas_20160601_cut_dense_3857 AS ia
	ON ST_Intersects(c.shape, ia.geom)
	WHERE ia.subdivisio=ANY(ARRAY['32','29','28','27'])
),
excluded_basins AS (
    SELECT shape 
    FROM h_baltic_3031.catchments
    UNION ALL
    SELECT shape 
    FROM h_baltic_3229_27.catchments
    UNION ALL
    SELECT shape 
    FROM h_baltic_26_22.catchments
),
filtered_basin AS (
    SELECT lb.*
    FROM last_basin lb
    LEFT JOIN excluded_basins exb
    ON lb.shape && exb.shape
    AND ST_Equals(lb.shape, exb.shape)
    WHERE exb.shape IS NULL
)
INSERT INTO h_baltic_3229_27.catchments
SELECT *
FROM filtered_basin;
```

![Map of catchemnts on the Baltic with missing islands basins.](images/fig-missing_baltic2732.png "A view of the Baltic with missing islands"){#fig-missing_baltic2732}

![Map of catchemnts on the Baltic without missing islands basins.](images/fig-full_baltic2732.png "A view of the Baltic without missing islands"){#fig-full_baltic2732}

![Final map of catchments from HydroSHEDS split into ICES areas and ecoregions.](images/fig-final.png "A view of Europe and Northern Africa catchments"){#fig-final}


## Creating a hierarchical structure 

```{dot}
//| label: fig-area_hierarchy
//| fig-cap: The nested structure layed out in table tr_area_area, dotted box indicate that the level is optional. This table will be created specifically for each group.


digraph {
    compound=true;
    newrank=true;

    subgraph clusterA {
      label = Panpopulation
      style=full
      color=black
      center=true

      subgraph clusterB {
        label = Complex
        style=dashed
        color=black
        center=true

              subgraph clusterC {
              label = Stock
              style=dashed
              color=black
              center=true
    
                subgraph clusterD {
                  label = Country
                  style=dashed
                  color=firebrick
                  fontcolor=firebrick
                  center=true

                  subgraph clusterE {
                    label = Assessment_unit
                    style=full
                    color=green 
                    fontcolor=green
                    
                      subgraph clusterF {
                        label = Regional;
                        style=dashed
                        color=green4
                        fontcolor=green4
                        
                          subgraph clusterG {
                            label = River
                            style=dashed
                            color=green3
                            fontcolor=green3
                            
                                subgraph clusterH {
                                        label = River_section
                                        style=dashed
                                        color=green2
                                        fontcolor=green2
                                            section [
                                                label=data,
                                                shape=box, 
                                                style =invis
                                                ]
                                }
                          }
                      }
                  }
                }
              }
        subgraph clusterZ{
          label=Major
          style=dashed
          color=royalblue4
          fontcolor=royalblue4
          
                subgraph clusterY{
                    label=Subareas
                    style=dashed
                    color=royalblue3
                    fontcolor=royalblue3
                    
                        subgraph clusterX{
                            label=Division
                            style=dashed
                            color=royalblue2
                            fontcolor=royalblue2
                            
                                subgraph clusterW{
                                    label=Sudivision
                                    style=full
                                    color=royalblue1
                                    fontcolor=royalblue1
                                    
                                       subgraph clusterV{
                                           label=Unit
                                            style=dashed
                                            color=deepskyblue
                                            fontcolor=deepskyblue
                                            
                                                Fishing [
                                                    style=invis]
                                       }
                                }
                        }
                }            
        }          
      }}}
```

![Map of the full stock level.](images/fig-full_stock_level.png "A view of of the Baltic with a polygon surrounding the stock hierarchical level"){#fig-fullstocklvl}
(@fig-inlandstocklvl) (@fig-marinestocklvl)
### Marine level

```{sql}
#| eval: FALSE
#| echo: TRUE
#| code-summary: Code to create the marine stock level in the Baltic
#| warning: FALSE
#| message: FALSE

INSERT INTO refbast.tr_area_are (are_id, are_are_id, are_code, are_lev_code, are_ismarine, geom)
SELECT nextval('refbast.seq') AS are_id,
	1 AS are_are_id,
	'Baltic marine' AS are_code,
	'Stock' AS are_lev_code,
	--are_wkg_code,  by default
	true AS are_ismarine,
	ST_Union(geom) AS geom
	FROM ref.tr_fishingarea_fia 
	WHERE"fia_level"='Division' AND "fia_division" IN ('27.3.b, c','27.3.d');
```

![Map of the marine stock level.](images/fig-marine_stock_level.png "A view of of the Baltic with a polygon surrounding the Baltic Sea, Bothian Sea and Finland Gulf"){#fig-marinestocklvl}

```{sql}
#| eval: FALSE
#| echo: TRUE
#| code-summary: Code to create the ICES division level in the Baltic
#| warning: FALSE
#| message: FALSE

INSERT INTO refbast.tr_area_are (are_id, are_are_id, are_code, are_lev_code, are_ismarine, geom)
WITH select_division AS (
	SELECT geom FROM ref.tr_fishingarea_fia tff
	WHERE tff.fia_level = 'Division' AND tff.fia_division = '27.3.b, c'
)
SELECT nextval('refbast.seq') AS are_id,
		3 AS are_are_id,
		'27.3.b, c' AS are_code,
		'Division' AS are_lev_code,
		--are_wkg_code,
		true AS is_marine,
		geom AS geom
		FROM select_division;
```

```{sql}
#| eval: FALSE
#| echo: TRUE
#| code-summary: Code to create a function to add all ICES subdivisions level in the Baltic
#| warning: FALSE
#| message: FALSE

CREATE OR REPLACE FUNCTION insert_fishing_subdivision(subdiv TEXT, p_are_are_id INT)
RETURNS VOID AS 
$$
DECLARE 
  p_are_code TEXT;
BEGIN
  p_are_code := '27.3.' || subdiv;

  EXECUTE '
    INSERT INTO refbast.tr_area_are (are_id, are_are_id, are_code, are_lev_code, are_ismarine, geom)
    WITH select_subdivision AS (
      SELECT geom FROM ref.tr_fishingarea_fia tff 
      WHERE tff.fia_level = ''Subdivision'' AND tff.fia_subdivision = ''' || p_are_code || '''
    )
    SELECT nextval(''refbast.seq'') AS are_id,
           ' || p_are_are_id || ' AS are_are_id,
           ''' || p_are_code || ''' AS are_code,
           ''Subdivision'' AS are_lev_code,
           true AS is_marine,
           geom AS geom
    FROM select_subdivision;
  ';
END;
$$ LANGUAGE plpgsql;
```

![Map of the ICES subdivision level.](images/fig-marine_subdivision_level.png "A view of of the Baltic with polygons surrounding each ICES subdivisions"){#fig-marinesubdivlvl}




### Continental level

```{sql}
#| eval: FALSE
#| echo: TRUE
#| code-summary: Code to create the inland stock level in the Baltic
#| warning: FALSE
#| message: FALSE

INSERT INTO refbast.tr_area_are (are_id, are_are_id, are_code, are_lev_code, are_ismarine, geom)
SELECT nextval('refbast.seq') AS are_id,
	1 AS are_are_id,
	'Baltic inland' AS are_code,
	'Stock' AS are_lev_code,
	--are_wkg_code,  by default
	false AS are_ismarine,
	ST_Union(shape) AS geom
	FROM tempo.catchments_baltic
	WHERE rtrim(tableoid::regclass::text, '.catchments') IN ('h_baltic30to31', 'h_baltic22to26', 'h_baltic27to29_32');
```

![Map of the inland stock level.](images/fig-inland_stock_level.png "A view of Scandinavia with a polygon surrounding the inland stock hierarchical level"){#fig-inlandstocklvl}

```{sql}
#| eval: FALSE
#| echo: TRUE
#| code-summary: Code to create the country level in the Baltic
#| warning: FALSE
#| message: FALSE

CREATE OR REPLACE FUNCTION insert_country_baltic(country TEXT)
RETURNS VOID AS 
$$
BEGIN
  EXECUTE '
    INSERT INTO refbast.tr_area_are (are_id, are_are_id, are_code, are_lev_code, are_ismarine, geom)
    WITH country_selection AS (
      SELECT ST_Union(tbc.shape) AS geom, rc.cou_country
      FROM tempo.catchments_baltic tbc
      JOIN ref.tr_country_cou rc 
      ON ST_Intersects(tbc.shape, rc.geom)
      WHERE rc.cou_country = ''' || country || '''
      GROUP BY rc.cou_country
    )
    SELECT nextval(''refbast.seq'') AS are_id,
           3 AS are_are_id,
           ''' || country || ''' AS are_code,
           ''Country'' AS are_lev_code,
           false AS are_ismarine,
           geom AS geom
    FROM country_selection;
  ';
END;
$$ LANGUAGE plpgsql;

SELECT insert_country_baltic('Finland');
SELECT insert_country_baltic('Sweden');
SELECT insert_country_baltic('Estonia');
SELECT insert_country_baltic('Latvia');
SELECT insert_country_baltic('Lithuania');
SELECT insert_country_baltic('Poland');
SELECT insert_country_baltic('Germany');
SELECT insert_country_baltic('Denmark');
SELECT insert_country_baltic('Russia');
```

![Map of the country level.](images/fig-country_level.png "A view of Scandinavia with polygons surrounding each countries that has a catchment flowing into the Baltic"){#fig-countrylvl}

```{sql}
#| eval: FALSE
#| echo: TRUE
#| code-summary: Code to create the BAST assessment unit level in the Baltic
#| warning: FALSE
#| message: FALSE

INSERT INTO refbast.tr_area_are (are_id, are_are_id, are_code, are_lev_code, are_ismarine, geom)
WITH unit_selection AS (
	SELECT trc.geom AS geom, trc.main_riv
	FROM tempo.riversegments_baltic trc, janis.bast_assessment_units jau
	WHERE ST_Intersects(trc.geom, jau.geom) AND trc.ord_clas = 1 AND jau."Ass_unit" = 1
),
retrieve_rivers AS(
	SELECT DISTINCT trc.geom
	FROM tempo.riversegments_baltic trc, unit_selection us
	WHERE trc.main_riv IN (SELECT main_riv FROM unit_selection)
),
retrieve_catchments AS (
	SELECT DISTINCT ST_Union(tbc.shape) AS geom
	FROM tempo.catchments_baltic tbc, retrieve_rivers rr
	WHERE ST_Intersects(tbc.shape,rr.geom)
)
SELECT nextval('refbast.seq') AS are_id,
		3 AS are_are_id,
		'1 Northeastern Bothnian Bay' AS are_code,
		'Assessment_unit' AS are_lev_code,
		--are_wkg_code,
		false AS is_marine,
		ST_Union(geom) AS geom
		FROM retrieve_catchments;
```

![Map of WGBAST assessment units.](images/fig-assunit.png "A view of Scandinavia with polygons surrounding each countries that has a catchment flowing into the Baltic"){#fig-bastassunit}

![Map of WGBAST assessment units level.](images/fig-assunit_level.png "A view of Scandinavia with polygons surrounding each countries that has a catchment flowing into the Baltic"){#fig-assunitlvl}

```{sql}
#| eval: FALSE
#| echo: TRUE
#| code-summary: Code to create a function for the main river level in the Baltic 30-31 area
#| warning: FALSE
#| message: FALSE

CREATE OR REPLACE FUNCTION insert_area_are(p_are_are_id INT, p_ass_unit INT) 
RETURNS VOID AS $$
BEGIN
  WITH unit_riv AS (
    SELECT DISTINCT trc.main_riv
    FROM tempo.riversegments_baltic trc
    JOIN janis.bast_assessment_units jau
      ON ST_Intersects(trc.geom, jau.geom)
    WHERE trc.ord_clas = 1
      AND jau."Ass_unit" = p_ass_unit
  ),
  all_segments AS (
    SELECT trc.main_riv, trc.geom
    FROM tempo.riversegments_baltic trc
    JOIN unit_riv ur ON ur.main_riv = trc.main_riv
  ),
  catchments_with_riv AS (
    SELECT DISTINCT tcb.hybas_id, trc.main_riv, tcb.shape
    FROM tempo.catchments_baltic tcb
    JOIN all_segments trc ON ST_Intersects(tcb.shape, trc.geom)
  ),
  deduplicated AS (
    SELECT DISTINCT ON (hybas_id) main_riv, hybas_id, shape
    FROM catchments_with_riv
  ),
  merged AS (
    SELECT main_riv, ST_Union(shape) AS geom
    FROM deduplicated
    GROUP BY main_riv
  )
  INSERT INTO refbast.tr_area_are (
    are_id, are_are_id, are_code, are_lev_code, are_ismarine, geom
  )
  SELECT 
    nextval('refbast.seq'),
    p_are_are_id,
    main_riv,
    'River',
    false,
    geom
  FROM merged
  WHERE geom IS NOT NULL;
  
END;
$$ LANGUAGE plpgsql;
```

![Map of WGBAST assessment units level.](images/fig-riverlevel.png "A view of Scandinavia with polygons surrounding each countries that has a catchment flowing into the Baltic"){#fig-riverlvl}


WIP - river section level / fixing issues with overlapping polygons

# EU-Hydro
## Data description
**EU-Hydro** is a pan-European hydrographic dataset developed under the Copernicus Land Monitoring Service. It provides a detailed and consistent interpretation of surface water bodies and river networks across 39 European Environment Agency (EEA) countries. Based on high-resolution remote sensing imagery from 2006, 2009, and 2012, EU-Hydro includes a photo-interpreted river network, inland water bodies, canals, and ditches. From version 1.2, it integrates river segments derived from the EU Digital Elevation Model (EU-DEM), improving the completeness and accuracy of the dataset. It serves as a key resource for environmental monitoring, water resource management, and hydrological studies at the European level.

```{r}
#| label: river segment variables
#| code-summary: Description of river segments variables
#| echo: TRUE
#| warning: FALSE
#| message: FALSE
#| tbl-cap: Variables description


data_description <- dbGetQuery(con_diaspara, 
  "SELECT cols.column_name AS var_name, 
        pgd.description AS description
  FROM information_schema.columns cols
  LEFT JOIN pg_catalog.pg_statio_all_tables st 
      ON st.schemaname = cols.table_schema AND st.relname = cols.table_name
  LEFT JOIN pg_catalog.pg_description pgd 
      ON pgd.objoid = st.relid AND pgd.objsubid = cols.ordinal_position
  WHERE cols.table_schema = 'e_gota'
  AND cols.table_name = 'euhydro_gota_v013 — River_Net_l';")

knitr::kable(data_description) %>% kable_styling(bootstrap_options = c("striped", "hover", "condensed"))

```

We will also be using a Nodes layer that contains informations on the source, the outlet and the branching tributaries of rivers.

## Importing EU-Hydro
To be decided. We cannot make it work at the moment

## Building the database
The EU-Hydro data is split into several schemas following main basins. River segments, canals, ditches and inland waters are divided into several tables. The first work will be done on river segments. Other data will be added later on.

![Map of river network from EU-Hydro split into basins.](images/fig-euhydrobase.png "A view of Europe river networks"){#fig-eubase}

The river network will be devided following the same idea as for HydroSHEDS'. ICES Areas and Ecoregions will be used as a base layer to create different schemas.

### Step 1 : Restructuring and fixing issues
To be able to properly integrate data to our database, some changes have been made on the data. To make those changes, functions have been created.

Firstly, the SRID and geometry had to be switched from 3035 to 4326 and from 3D to 2D (the z-dimension of the geometry being always equals to 0).

```{sql}
#| eval: FALSE
#| echo: TRUE
#| code-summary: Code to create a function that changes srid and geometry
#| warning: FALSE
#| message: FALSE

DROP FUNCTION IF EXISTS altergeometry(basin TEXT);
CREATE OR REPLACE FUNCTION altergeometry(basin TEXT)
RETURNS TABLE (table_name TEXT, srid INTEGER) AS
$$
DECLARE 
    schema_name TEXT := quote_ident('e_' || basin);
    river_table TEXT := quote_ident('euhydro_' || basin || '_v013 — River_Net_l');
    nodes_table TEXT := quote_ident('euhydro_' || basin || '_v013 — Nodes');
    sql_query TEXT;
BEGIN 
    sql_query := 
        'ALTER TABLE ' || schema_name || '.' || river_table || 
        ' ALTER COLUMN geom TYPE geometry(MultiLineString, 4326) 
          USING ST_Transform(ST_Force2D(geom), 4326);';
    EXECUTE sql_query;
    sql_query := 
        'ALTER TABLE ' || schema_name || '.' || nodes_table || 
        ' ALTER COLUMN geom TYPE geometry(Point, 4326) 
          USING ST_Transform(ST_Force2D(geom), 4326);';
    EXECUTE sql_query;

	RETURN QUERY EXECUTE 
        'SELECT ' || quote_literal(river_table) || ' AS table_name, srid 
         FROM (SELECT DISTINCT ST_SRID(geom) AS srid FROM ' || schema_name || '.' || river_table || ') sub
         UNION ALL 
         SELECT ' || quote_literal(nodes_table) || ' AS table_name, srid 
         FROM (SELECT DISTINCT ST_SRID(geom) AS srid FROM ' || schema_name || '.' || nodes_table || ') sub;';
END;
$$ LANGUAGE plpgsql;
```

Then, a function to restructure the column order of the river segment tables was created to harmonise tables' structure between different basins.

```{sql}
#| eval: FALSE
#| echo: TRUE
#| code-summary: Code to restructure columns order
#| warning: FALSE
#| message: FALSE

DROP FUNCTION IF EXISTS restructurecolumns(basin TEXT);
CREATE OR REPLACE FUNCTION restructurecolumns(basin TEXT)
RETURNS VOID AS $$
DECLARE 
    schema_name TEXT := quote_ident('e_' || basin);
    source_table TEXT := quote_ident('euhydro_' || basin || '_v013 — River_Net_l');
    target_table TEXT := quote_ident('riverseg');
    sql_query TEXT;
BEGIN
    sql_query := 
        'CREATE TABLE ' || schema_name || '.' || target_table || ' AS SELECT ' ||
        '"OBJECTID",
         geom,
         "DFDD",
         "RN_I_ID",
         "REX",
         "HYP",
         "LOC",
         "FUN",
         "NVS",
         "LENGTH",
         "TR",
         "LONGPATH",
         "CUM_LEN",
         "PENTE",
         "CGNELIN",
         "BEGLIFEVER",
         "ENDLIFEVER",
         "UPDAT_BY",
         "UPDAT_WHEN",
         "ERM_ID",
         "MC",
         "MONOT_Z",
         "LENGTH_GEO",
         "INSPIRE_ID",
         "thematicId",
         "OBJECT_ID",
         "TNODE",
         "STRAHLER",
         "nameTxtInt",
         "nameText",
         "NEXTUPID",
         "NEXTDOWNID",
         "FNODE",
         "CatchID",
         "Shape_Length",
         "PFAFSTETTER" ' ||
        ' FROM ' || schema_name || '.' || source_table;

    EXECUTE sql_query;
END;
$$ LANGUAGE plpgsql;
```

Finally, indexes and unicity constraints are added to variables that will be used to divide the dataset as well as river segments ids.

```{sql}
#| eval: FALSE
#| echo: TRUE
#| code-summary: Code to retrieve all missing islands and coastal catchments
#| warning: FALSE
#| message: FALSE

DROP FUNCTION IF EXISTS create_indexes_and_constraint(basin TEXT);
CREATE OR REPLACE FUNCTION create_indexes_and_constraint(basin TEXT)
RETURNS VOID AS
$$
DECLARE 
    schema_name TEXT := quote_ident('e_' || basin);
    river_table TEXT := quote_ident('euhydro_' || basin || '_v013 — River_Net_l');
    sql_query TEXT;
BEGIN 
    sql_query := 
        'CREATE INDEX IF NOT EXISTS idx_t_node_' || basin || '_riv 
         ON ' || schema_name || '.' || river_table || ' USING btree("TNODE");';
    EXECUTE sql_query;
    sql_query := 
        'CREATE INDEX IF NOT EXISTS idx_next_did_' || basin || '_riv 
         ON ' || schema_name || '.' || river_table || ' USING btree("NEXTDOWNID");';
    EXECUTE sql_query;
    sql_query := 
        'CREATE INDEX IF NOT EXISTS idx_obj_id_' || basin || ' 
         ON ' || schema_name || '.' || river_table || ' USING btree("OBJECT_ID");';
    EXECUTE sql_query;
    sql_query := 
        'ALTER TABLE ' || schema_name || '.' || river_table || ' 
         ADD CONSTRAINT c_uk_object_id_' || basin || ' UNIQUE("OBJECT_ID");';
    EXECUTE sql_query;
END;
$$ LANGUAGE plpgsql;
```


### Step 2: Selecting outlets
We create the table `tempo.selected_tnodes_balt_3031` to identify river outlet nodes near ICES marine subdivisions 31 and 30 in the Baltic region. First, in the `select_outlet` CTE, we extract nodes where `"HYDRONODCT" = 'Outlet'` from the Neva, Angerman, Kemi, and Gota river networks. Then, in `ices_nodes`, we filter these outlet nodes by checking if they are within `ST_DWithin(sr.geom, ia.geom, 0.04)` of ICES marine areas. Finally, in `select_riv`, we retrieve river segments from `"euhydro_*_v013 — River_Net_l"` tables that are connected to the selected outlet nodes via `"TNODE" = ir."OBJECT_ID"`, ensuring only distinct entries are included in the final table.

```{sql}
#| eval: FALSE
#| echo: TRUE
#| code-summary: Code to retrieve river segments outlets for basins within range of ICES subdivisions 30 and 31
#| warning: FALSE
#| message: FALSE

DROP TABLE IF EXISTS tempo.selected_tnodes_balt_3031;
CREATE TABLE tempo.selected_tnodes_balt_3031 AS
WITH select_outlet AS (
    SELECT * FROM e_neva."euhydro_neva_v013 — Nodes" WHERE "HYDRONODCT" = 'Outlet'
    UNION ALL
    SELECT * FROM e_angerman."euhydro_angerman_v013 — Nodes" WHERE "HYDRONODCT" = 'Outlet'
    UNION ALL
    SELECT * FROM e_kemi."euhydro_kemi_v013 — Nodes" WHERE "HYDRONODCT" = 'Outlet'
    UNION ALL
    SELECT * FROM e_gota."euhydro_gota_v013 — Nodes" WHERE "HYDRONODCT" = 'Outlet'
),
ices_nodes AS (
    SELECT sr.*
    FROM select_outlet sr
    JOIN ices_areas.ices_areas_20160601_cut_dense_3857 AS ia
    ON ST_DWithin(sr.geom, ia.geom, 0.04)
    WHERE ia.subdivisio = ANY(ARRAY['31','30'])
),
select_riv AS (
    SELECT enr.*
    FROM e_neva."euhydro_neva_v013 — River_Net_l" enr
    JOIN ices_nodes ir ON enr."TNODE" = ir."OBJECT_ID"
    UNION ALL
    SELECT enr.*
    FROM e_angerman."euhydro_angerman_v013 — River_Net_l" enr
    JOIN ices_nodes ir ON enr."TNODE" = ir."OBJECT_ID"
    UNION ALL
    SELECT enr.*
    FROM e_kemi."euhydro_kemi_v013 — River_Net_l" enr
    JOIN ices_nodes ir ON enr."TNODE" = ir."OBJECT_ID"
    UNION ALL
    SELECT enr.*
    FROM e_gota."euhydro_gota_v013 — River_Net_l" enr
    JOIN ices_nodes ir ON enr."TNODE" = ir."OBJECT_ID"
)
SELECT DISTINCT ON ("OBJECT_ID") "OBJECT_ID" AS seaoutlet, select_riv.* FROM select_riv;
```

### Step 3: Merging basins
To facilitate the next query, all basins touching the selected ICES areas have been merged into a temporary table. While doing to the name of the basin is added to the table.

```{sql}
#| eval: FALSE
#| echo: TRUE
#| code-summary: Code to merge all riversegments into one table
#| warning: FALSE
#| message: FALSE

DROP TABLE IF EXISTS tempo.e_balt_3031;
CREATE TABLE tempo.e_balt_3031 AS(
	SELECT *, 'neva' AS basin FROM e_neva."euhydro_neva_v013 — River_Net_l"
	    UNION ALL
	    SELECT *, 'angerman' AS basin FROM e_angerman."euhydro_angerman_v013 — River_Net_l"
	    UNION ALL
	    SELECT *, 'kemi' AS basin FROM e_kemi."euhydro_kemi_v013 — River_Net_l"
	    UNION ALL
	    SELECT *, 'gota' AS basin FROM e_gota."euhydro_gota_v013 — River_Net_l"
);
```


![Map of river network from EU-Hydro and selected outlets in the Baltic for ICES subdivisions 30 & 31.](images/fig-euhydrooutlets.png "A view of selected outlets for Baltic subdivisions 30 & 31"){#fig-euoutlets}

### Step 4: Retrieving river segments
To facilitate the workflow we created a function to retrieve all river segments linked to the outlet segments. This function also modify all variables names to harmonize them with the rest of the database.

We create the function `makesegments(schema text, outlet_table text, segment_table text)` to recursively trace river segments upstream from specified outlet nodes. In the returned variables we decided to keep the `"OBJECT_ID"` of each outlet's river segment as `seaoutlet`. Inside the function, we define the recursive CTE `river_tree`, which starts by selecting river segments where `"TNODE"` matches `"TNODE"` from the outlet table. It then iteratively joins upstream segments using `"NEXTDOWNID"`, tracking depth and preventing cycles using `is_cycle` and `path`. Finally, we return all river segments along with their associated `seaoutlet`.

```{sql}
#| eval: FALSE
#| echo: TRUE
#| code-summary: Code to retrieve all river segments linked to preselected outlets
#| warning: FALSE
#| message: FALSE

DROP FUNCTION IF EXISTS makesegments(schema text, outlet_table text, segment_table text);
CREATE FUNCTION makesegments(schema text, outlet_table text, segment_table text)
RETURNS TABLE(
    objectid bigint,
    geom public.geometry,
    dfdd character varying(5),
    rn_i_id character varying(256),
    rex character varying(256),
    hyp integer,
    loc integer,
    fun integer,
    nvs integer,
    length double precision,
    tr character varying(10),
    longpath double precision,
    cum_len double precision,
    pente double precision,
    cgnelin integer,
    beglifever timestamp without time zone,
    endlifever timestamp without time zone,
    updat_by character varying(15),
    updat_when timestamp without time zone,
    erm_id character varying(256),
    mc integer,
    monot_z integer,
    length_geo double precision,
    inspire_id character varying(256),
    thematicid character varying(42),
    object_id character varying(255),
    tnode character varying(255),
    strahler double precision,
    nametxtint character varying(254),
    nametext character varying(254),
    nextupid character varying(255),
    nextdownid character varying(255),
    fnode character varying(255),
    catchid integer,
    shape_length double precision,
    pfafstetter character varying(255),
    basin text,
    seaoutlet character varying(255)
) 
AS
$$
DECLARE 
	schema TEXT := quote_ident(schema::text);
    seg_table TEXT := quote_ident(segment_table::text);
    out_table TEXT := quote_ident(outlet_table::text);
    sql_query TEXT;
BEGIN 
    sql_query := 
    'WITH RECURSIVE river_tree ("OBJECTID", "NEXTDOWNID", "OBJECT_ID", seaoutlet, basin, depth, is_cycle, path) AS (
        SELECT enr."OBJECTID", enr."NEXTDOWNID", enr."OBJECT_ID", ttn.seaoutlet, enr.basin, 0, FALSE, 
            ARRAY[enr."OBJECT_ID"]::varchar[]
        FROM ' ||schema||'.'|| seg_table || ' enr
        JOIN ' ||schema||'.'|| out_table || ' ttn ON enr."TNODE" = ttn."TNODE"
        UNION ALL
        SELECT enr."OBJECTID", enr."NEXTDOWNID", enr."OBJECT_ID", rt.seaoutlet, rt.basin, rt.depth+1,
            enr."OBJECT_ID" = ANY(path),
            path || ARRAY[rt."OBJECT_ID"]
        FROM ' ||schema||'.'|| seg_table || ' enr
        JOIN river_tree rt ON enr."NEXTDOWNID" = rt."OBJECT_ID" AND NOT is_cycle
    )
    SELECT en.*, river_tree.seaoutlet
    FROM ' ||schema||'.'|| seg_table || ' en
    JOIN river_tree ON (en."OBJECTID", en.basin) = (river_tree."OBJECTID", river_tree.basin)';

    RETURN QUERY EXECUTE sql_query;
END
$$ LANGUAGE plpgsql;
```

![Map of river network from EU-Hydro for the Baltic ICES subdivisions 30 & 31.](images/fig-euhydrobalt3031.png "A view of the Baltic river networks for ICES subdivisions 30 & 31"){#fig-eubalt3031}

The same method is applied for all basins using either ICES subdivision or ICES ecoregions.

WIP - Issues with some basins to fix
![Map of river network from EU-Hydro split into ICES areas.](images/fig-euhydroices.png "A view of Europe river networks"){#fig-eubase}

# Acknowlegment

HydroSHEDS : Lehner, B., Verdin, K., Jarvis, A. (2008). New global hydrography derived from spaceborne elevation data. Eos, Transactions, American Geophysical Union, 89(10): 93–94. https://doi.org/10.1029/2008eo100001

EU-Hydro : COPERNICUS Land Monitoring Service, 2019: EU-Hydro. Last access: 24/03/2025
https://land.copernicus.eu/imagery-in-situ/eu-hydro

